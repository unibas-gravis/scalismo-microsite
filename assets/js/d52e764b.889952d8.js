"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[433],{3905:function(e,t,a){a.d(t,{Zo:function(){return c},kt:function(){return u}});var n=a(7294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var l=n.createContext({}),d=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},c=function(e){var t=d(e.components);return n.createElement(l.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,o=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),m=d(a),u=i,h=m["".concat(l,".").concat(u)]||m[u]||p[u]||o;return a?n.createElement(h,r(r({ref:t},c),{},{components:a})):n.createElement(h,r({ref:t},c))}));function u(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var o=a.length,r=new Array(o);r[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:i,r[1]=s;for(var d=2;d<o;d++)r[d]=a[d];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},275:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return s},contentTitle:function(){return l},metadata:function(){return d},toc:function(){return c},default:function(){return m}});var n=a(7462),i=a(3366),o=(a(7294),a(3905)),r=["components"],s={id:"tutorial06",title:"Building a shape model from data"},l=void 0,d={unversionedId:"Tutorials/tutorial06",id:"Tutorials/tutorial06",title:"Building a shape model from data",description:"The goal in this tutorial is to learn how to build a Statistical Shape Model",source:"@site/docs/Tutorials/tutorial06.md",sourceDirName:"Tutorials",slug:"/Tutorials/tutorial06",permalink:"/docs/next/Tutorials/tutorial06",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Tutorials/tutorial06.md",tags:[],version:"current",frontMatter:{id:"tutorial06",title:"Building a shape model from data"},sidebar:"docs",previous:{title:"Gaussian processes, sampling and marginalization",permalink:"/docs/next/Tutorials/tutorial05"},next:{title:"Shape modelling with Gaussian processes and kernels",permalink:"/docs/next/Tutorials/tutorial07"}},c=[{value:"Related resources",id:"related-resources",children:[],level:5},{value:"Preparation",id:"preparation",children:[],level:5},{value:"Loading and preprocessing a dataset:",id:"loading-and-preprocessing-a-dataset",children:[{value:"Rigidly aligning the data:",id:"rigidly-aligning-the-data",children:[],level:4}],level:3},{value:"Building a discrete Gaussian process from data",id:"building-a-discrete-gaussian-process-from-data",children:[],level:3},{value:"An easier way to build a model.",id:"an-easier-way-to-build-a-model",children:[],level:3}],p={toc:c};function m(e){var t=e.components,s=(0,i.Z)(e,r);return(0,o.kt)("wrapper",(0,n.Z)({},p,s,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"The goal in this tutorial is to learn how to build a Statistical Shape Model\nfrom meshes in correspondence. Furthermore, we discuss the importance of rigid alignment while doing so."),(0,o.kt)("h5",{id:"related-resources"},"Related resources"),(0,o.kt)("p",null,"The following resources from our ",(0,o.kt)("a",{parentName:"p",href:"https://www.futurelearn.com/courses/statistical-shape-modelling"},"online course")," may provide\nsome helpful context for this tutorial:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Learning a model from example data ",(0,o.kt)("a",{parentName:"li",href:"https://www.futurelearn.com/courses/statistical-shape-modelling/3/steps/250329"},"(Video)"))),(0,o.kt)("p",null,"To run the code from this tutorial, download the following Scala file:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{target:"_blank",href:a(864).Z},"Tutorial06.scala"))),(0,o.kt)("h5",{id:"preparation"},"Preparation"),(0,o.kt)("p",null,"As in the previous tutorials, we start by importing some commonly used objects and initializing the system."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},"import scalismo.ui.api._\n\nimport scalismo.geometry._\nimport scalismo.common._\nimport scalismo.common.interpolation.TriangleMeshInterpolator3D\nimport scalismo.mesh._\nimport scalismo.io.{StatisticalModelIO, MeshIO}\nimport scalismo.statisticalmodel._\nimport scalismo.registration._\nimport scalismo.statisticalmodel.dataset._\nimport scalismo.numerics.PivotedCholesky.RelativeTolerance\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},"scalismo.initialize()\nimplicit val rng: scalismo.utils.Random = scalismo.utils.Random(42)\n\nval ui = ScalismoUI()\n")),(0,o.kt)("h3",{id:"loading-and-preprocessing-a-dataset"},"Loading and preprocessing a dataset:"),(0,o.kt)("p",null,"Let us load (and visualize) a set of face meshes based on which we would like to model shape variation:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'val dsGroup = ui.createGroup("datasets")\n\nval meshFiles = new java.io.File("datasets/nonAlignedFaces/").listFiles\nval (meshes, meshViews) = meshFiles.map(meshFile => {\n  val mesh = MeshIO.readMesh(meshFile).get\n  val meshView = ui.show(dsGroup, mesh, "mesh")\n  (mesh, meshView) // return a tuple of the mesh and the associated view\n}) .unzip // take the tuples apart, to get a sequence of meshes and one of meshViews\n')),(0,o.kt)("p",null,"You immediately see that the meshes are not aligned. What you cannot see, but is\nvery important for this tutorial, is\nthat the meshes are ",(0,o.kt)("strong",{parentName:"p"},"in correspondence"),".\nThis means that for every point on one of the face meshes\n(corner of eye, tip of nose, ...), we can identify the corresponding point on\nother meshes.  Corresponding points are identified by the same point id."),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},"Exercise: verify that the meshes are indeed in correspondence by displaying a few corresponding points.")),(0,o.kt)("h4",{id:"rigidly-aligning-the-data"},"Rigidly aligning the data:"),(0,o.kt)("p",null,"In order to study shape variations, we need to eliminate variations due to\nrelative spatial displacement of the shapes (rotation and translation).\nThis can be achieved by selecting one of the meshes as a reference,\nto which the rest of the datasets are aligned.\nIn this example here, we simply take the first mesh in the list as a reference and align all the others."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},"val reference = meshes.head\nval toAlign : IndexedSeq[TriangleMesh[_3D]] = meshes.tail\n")),(0,o.kt)("p",null,"Given that our dataset is in correspondence, we can specify a set of point\nidentifiers, to locate corresponding points on the meshes."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'val pointIds = IndexedSeq(2214, 6341, 10008, 14129, 8156, 47775)\nval refLandmarks = pointIds.map{id => Landmark(s"L_$id", reference.pointSet.point(PointId(id))) }\n')),(0,o.kt)("p",null,"After locating the landmark positions on the reference, we iterate on each remaining data item, identify the corresponding landmark points and then rigidly align the mesh to the reference."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'val alignedMeshes = toAlign.map { mesh =>\n  val landmarks = pointIds.map{id => Landmark("L_"+id, mesh.pointSet.point(PointId(id)))}\n  val rigidTrans = LandmarkRegistration.rigid3DLandmarkRegistration(landmarks, refLandmarks, center = Point(0,0,0))\n  mesh.transform(rigidTrans)\n}\n')),(0,o.kt)("p",null,"Now, the IndexedSeq of triangle meshes ",(0,o.kt)("em",{parentName:"p"},"alignedMeshes")," contains the faces that are aligned to the reference mesh."),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},"Exercise: verify visually that at least the first element of the aligned dataset is indeed aligned to the reference.")),(0,o.kt)("h3",{id:"building-a-discrete-gaussian-process-from-data"},"Building a discrete Gaussian process from data"),(0,o.kt)("p",null,"Now that we have a set of meshes, which are in correspondence and aligned\nto our reference, we can turn the dataset into a set of deformation fields,\nfrom which we then build the model:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},"val defFields = alignedMeshes.map{ m =>\n    val deformationVectors = reference.pointSet.pointIds.map{ (id : PointId) =>\n        m.pointSet.point(id) - reference.pointSet.point(id)\n    }.toIndexedSeq\n    DiscreteField3D(reference, deformationVectors)\n}\n")),(0,o.kt)("p",null,"Learning the shape variations from this deformation fields is\ndone by calling the method ",(0,o.kt)("inlineCode",{parentName:"p"},"createUsingPCA")," of the\n",(0,o.kt)("inlineCode",{parentName:"p"},"DiscreteLowRankGaussianProcess")," class.\nNote that the deformation fields need to be interpolated, such that we are sure that they are defined on\nall the points of the reference mesh. Once we have the deformation fields, we can build and\nvisualize the Point Distribution Model:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'val continuousFields = defFields.map(f => f.interpolate(TriangleMeshInterpolator3D()) )\nval gp = DiscreteLowRankGaussianProcess.createUsingPCA(reference,\n            continuousFields, RelativeTolerance(1e-8)\n          )\nval model = PointDistributionModel(gp)\nval modelGroup = ui.createGroup("model")\nval ssmView = ui.show(modelGroup, model, "model")\n')),(0,o.kt)("p",null,"Notice that when we visualize this mesh model in Scalismo-ui,\nit generates a GaussianProcessTransformation and the reference mesh in the\nScene Tree of Scalismo-ui."),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},"Exercise: display the mean deformation field of the returned Gaussian Process.")),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},"Exercise: sample and display a few deformation fields from this GP.")),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},"Exercise: using the GP's "),"cov",(0,o.kt)("em",{parentName:"p"}," method, evaluate the sample covariance between two close points on the right cheek first, and a point on the nose and one on the cheek second. What does the data tell you?")),(0,o.kt)("h3",{id:"an-easier-way-to-build-a-model"},"An easier way to build a model."),(0,o.kt)("p",null,"Performing all the operations above every time we want to build a PCA model\nfrom a set of files containing meshes in correspondence can be tedious.\nTherefore, Scalismo provides a more easy to use implementation via the\n",(0,o.kt)("em",{parentName:"p"},"DataCollection")," data structure."),(0,o.kt)("p",null,"The ",(0,o.kt)("em",{parentName:"p"},"DataCollection")," class in Scalismo allows grouping together a dataset of meshes in correspondence,\nin order to make collective operations on such sets easier."),(0,o.kt)("p",null,"We can create a ",(0,o.kt)("em",{parentName:"p"},"DataCollection")," by providing a reference mesh, and\na sequence of meshes, which are in correspondence with this reference."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},"val dc = DataCollection.fromTriangleMesh3DSequence(reference, alignedMeshes)\n")),(0,o.kt)("p",null,"Now that we have our data collection, we can build a shape model as follows:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'val modelFromDataCollection = PointDistributionModel.createUsingPCA(dc)\n\nval modelGroup2 = ui.createGroup("modelGroup2")\nui.show(modelGroup2, modelFromDataCollection, "ModelDC")\n')),(0,o.kt)("p",null,"There is a technique called ",(0,o.kt)("em",{parentName:"p"},"Generalized Procrustes Analysis (GPA)"),", which can\nimprove the alignment of the data even better. It works by computing\nthe mean of a set of surfaces in correspondence, aligning all the surfaces rigidly\nto this mean, and then iterating this procedure until the changes in the\ncomputed mean are below a certain threshold. In Scalismo, this alignment\nprocedure is defined on data collections. We can use it as follows:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'val dcWithGPAAlignedShapes = DataCollection.gpa(dc)\nval modelFromDataCollectionGPA = PointDistributionModel.createUsingPCA(dcWithGPAAlignedShapes)\n\nval modelGroup3 = ui.createGroup("modelGroup3")\nui.show(modelGroup3, modelFromDataCollectionGPA, "ModelDCGPA")\n')))}m.isMDXComponent=!0},864:function(e,t,a){t.Z=a.p+"assets/files/Tutorial06-640c1095602f42355ab6f7d6165de071.scala"}}]);