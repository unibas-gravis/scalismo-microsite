"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[5874],{3905:function(e,t,r){r.d(t,{Zo:function(){return m},kt:function(){return d}});var n=r(7294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function o(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function s(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?o(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},o=Object.keys(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var i=n.createContext({}),c=function(e){var t=n.useContext(i),r=t;return e&&(r="function"==typeof e?e(t):s(s({},t),e)),r},m=function(e){var t=c(e.components);return n.createElement(i.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,o=e.originalType,i=e.parentName,m=l(e,["components","mdxType","originalType","parentName"]),u=c(r),d=a,f=u["".concat(i,".").concat(d)]||u[d]||p[d]||o;return r?n.createElement(f,s(s({ref:t},m),{},{components:r})):n.createElement(f,s({ref:t},m))}));function d(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=r.length,s=new Array(o);s[0]=u;var l={};for(var i in t)hasOwnProperty.call(t,i)&&(l[i]=t[i]);l.originalType=e,l.mdxType="string"==typeof e?e:a,s[1]=l;for(var c=2;c<o;c++)s[c]=r[c];return n.createElement.apply(null,s)}return n.createElement.apply(null,r)}u.displayName="MDXCreateElement"},6011:function(e,t,r){r.r(t),r.d(t,{frontMatter:function(){return l},contentTitle:function(){return i},metadata:function(){return c},toc:function(){return m},default:function(){return u}});var n=r(7462),a=r(3366),o=(r(7294),r(3905)),s=["components"],l={id:"tutorial09",title:"Shape completion using GP regression"},i=void 0,c={unversionedId:"Tutorials/tutorial09",id:"version-0.92/Tutorials/tutorial09",title:"Shape completion using GP regression",description:"In this tutorial we will show how GP regression can be used to predict missing parts of a shape.",source:"@site/versioned_docs/version-0.92/Tutorials/tutorial09.md",sourceDirName:"Tutorials",slug:"/Tutorials/tutorial09",permalink:"/docs/Tutorials/tutorial09",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/versioned_docs/version-0.92/Tutorials/tutorial09.md",tags:[],version:"0.92",frontMatter:{id:"tutorial09",title:"Shape completion using GP regression"},sidebar:"docs",previous:{title:"Posterior shape models",permalink:"/docs/Tutorials/tutorial08"},next:{title:"Iterative Closest Points for rigid alignment",permalink:"/docs/Tutorials/tutorial10"}},m=[{value:"Related resources",id:"related-resources",children:[],level:5},{value:"Preparation",id:"preparation",children:[],level:5},{value:"Enlarging the flexibility of a shape model",id:"enlarging-the-flexibility-of-a-shape-model",children:[],level:2}],p={toc:m};function u(e){var t=e.components,l=(0,a.Z)(e,s);return(0,o.kt)("wrapper",(0,n.Z)({},p,l,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"In this tutorial we will show how GP regression can be used to predict missing parts of a shape."),(0,o.kt)("h5",{id:"related-resources"},"Related resources"),(0,o.kt)("p",null,"To enhance your understanding of this tutorial, we recommend the following resources from our ",(0,o.kt)("a",{parentName:"p",href:"https://shapemodelling.cs.unibas.ch/ssm-course/"},"online course"),":"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Covariance functions ",(0,o.kt)("a",{parentName:"li",href:"https://shapemodelling.cs.unibas.ch/ssm-course/week4/step4-2"},"(Video)")),(0,o.kt)("li",{parentName:"ul"},"Enlarging the flexibility of statistical shape models ",(0,o.kt)("a",{parentName:"li",href:"https://shapemodelling.cs.unibas.ch/ssm-course/week4/step4-7"},"(Article)")),(0,o.kt)("li",{parentName:"ul"},"The regression problem ",(0,o.kt)("a",{parentName:"li",href:"https://shapemodelling.cs.unibas.ch/ssm-course/week5/step5-2"},"(Article)")),(0,o.kt)("li",{parentName:"ul"},"Gaussian process regression ",(0,o.kt)("a",{parentName:"li",href:"https://shapemodelling.cs.unibas.ch/ssm-course/week5/step5-3"},"(Video)")),(0,o.kt)("li",{parentName:"ul"},"Posterior models for different kernels ",(0,o.kt)("a",{parentName:"li",href:"https://shapemodelling.cs.unibas.ch/ssm-course/week5/step5-4"},"(Article)"))),(0,o.kt)("p",null,"To run the code from this tutorial, download the following Scala file:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{target:"_blank",href:r(8891).Z},"Tutorial09.scala"))),(0,o.kt)("h5",{id:"preparation"},"Preparation"),(0,o.kt)("p",null,"As in the previous tutorials, we start by importing some commonly used objects and initializing the system."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},"import scalismo.geometry.*\nimport scalismo.common.*\nimport scalismo.common.interpolation.TriangleMeshInterpolator3D\nimport scalismo.mesh.*\nimport scalismo.io.{StatisticalModelIO, MeshIO, LandmarkIO}\nimport scalismo.statisticalmodel.*\nimport scalismo.numerics.UniformMeshSampler3D\nimport scalismo.kernels.*\nimport breeze.linalg.{DenseMatrix, DenseVector}\n\nimport scalismo.ui.api.*\n\nimport java.io.File\n\nimport scalismo.utils.Random.FixedSeed.randBasis\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},"  scalismo.initialize()\n\n  val ui = ScalismoUI()\n")),(0,o.kt)("p",null,"We also load a dataset that we want to reconstruct. In this case, it's a face without nose:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'  val noseless = MeshIO.readMesh(File("datasets/noseless.ply")).get\n\n  val targetGroup = ui.createGroup("target")\n  ui.show(targetGroup, noseless,"noseless")\n')),(0,o.kt)("p",null,"Finally, we also load the face model."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'  val smallModel = StatisticalModelIO.readStatisticalTriangleMeshModel3D(File("datasets/model.h5")).get\n')),(0,o.kt)("h2",{id:"enlarging-the-flexibility-of-a-shape-model"},"Enlarging the flexibility of a shape model"),(0,o.kt)("p",null,"The model, which we just loaded, was built from only a small dataset. Therefore, the chances that it manages to\nreconstruct the missing nose properly are rather slim."),(0,o.kt)("p",null,"To augment the shape variability of the model, we introduce some additional smooth shape deformations, modeled by a GP with a symmetric Gaussian kernel. This approach should be familiar from previous tutorials."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'  val scalarValuedKernel = GaussianKernel3D(70, scaleFactor = 3)\n\n  case class XmirroredKernel(kernel: PDKernel[_3D]) extends PDKernel[_3D]:\n      override def domain = EuclideanSpace3D\n      override def k(x: Point[_3D], y: Point[_3D]) = kernel(Point(x(0) * -1f, x(1), x(2)), y)  \n\n  def symmetrizeKernel(kernel: PDKernel[_3D]): MatrixValuedPDKernel[_3D] = \n    val xmirrored = XmirroredKernel(kernel)\n    val k1 = DiagonalKernel(kernel, 3)\n    val k2 = DiagonalKernel(xmirrored * -1f, xmirrored, xmirrored)\n    k1 + k2  \n\n  val gp = GaussianProcess[_3D, EuclideanVector[_3D]](symmetrizeKernel(scalarValuedKernel))\n\n  val lowrankGP = LowRankGaussianProcess.approximateGPCholesky(\n        smallModel.reference,\n        gp,\n        relativeTolerance = 0.5e-1,\n        interpolator = TriangleMeshInterpolator3D[EuclideanVector[_3D]]()\n  )\n  val model = PointDistributionModel.augmentModel(smallModel, lowrankGP)\n\n  val modelGroup = ui.createGroup("face model")\n  val ssmView = ui.show(modelGroup, model, "model")\n')),(0,o.kt)("p",null,"The mew model should now possess greater flexibility while still preserving the typical face-specific deformations."),(0,o.kt)("p",null,"It's worth noting that this step is primarily motivated by the fact that we only have 10 face examples available to construct the model. However, even when sufficient data is available, it might still be beneficial to slightly increase the flexibility of a model before attempting to reconstruct missing parts. This affords the model some extra flexibility to account for bias in the data and explain minor shape variations that were not prominent in the dataset."),(0,o.kt)("p",null,"Equipped with our new model, we will perform the reconstruction in three steps:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"We'll fit the face model to the given partial face using Gaussian process regression."),(0,o.kt)("li",{parentName:"ol"},"We'll restrict the model to the nose part by marginalizing and then select a suitable nose shape."),(0,o.kt)("li",{parentName:"ol"},"We'll choose a suitable nose from the model.")),(0,o.kt)("p",null,"As previously discussed, to perform GP regression, we need observations of the deformation vectors at certain points. In the next code, we'll load and visualize some landmarks:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'  val referenceLandmarks = LandmarkIO.readLandmarksJson3D(File("datasets/modelLandmarks.json")).get\n  val referencePoints : Seq[Point[_3D]] = referenceLandmarks.map(lm => lm.point)\n  val referenceLandmarkViews = referenceLandmarks.map(lm => ui.show(modelGroup, lm, s"lm-${lm.id}"))\n\n\n  val noselessLandmarks = LandmarkIO.readLandmarksJson3D(File("datasets/noselessLandmarks.json")).get\n  val noselessPoints : Seq[Point[_3D]] = noselessLandmarks.map(lm => lm.point)\n  val noselessLandmarkViews = noselessLandmarks.map(lm => ui.show(targetGroup, lm, s"lm-${lm.id}"))\n')),(0,o.kt)("p",null,"These correspondences define how each selected point of the\nmodel should be deformed to its corresponding point on the target mesh.\nIn other words, we ",(0,o.kt)("strong",{parentName:"p"},"observed")," a few deformation vectors at\nthe selected model points. We use these deformation vectors and build\na deformation field:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'  val domain = UnstructuredPointsDomain3D(referencePoints.toIndexedSeq)\n  val deformations = (0 until referencePoints.size).map(i => noselessPoints(i) - referencePoints(i) )\n  val defField = DiscreteField3D(domain, deformations)\n  ui.show(modelGroup, defField, "partial_Field")\n')),(0,o.kt)("p",null,"We can now perform GP regression and retrieve the rest of the deformation field fitting our observations:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'  val littleNoise = MultivariateNormalDistribution(DenseVector.zeros[Double](3), DenseMatrix.eye[Double](3) * 0.5)\n\n  val regressionData = for ((refPoint, noselessPoint) <- referencePoints zip noselessPoints) yield\n    val refPointId = model.reference.pointSet.findClosestPoint(refPoint).id\n    (refPointId, noselessPoint, littleNoise)  \n\n  val posterior = model.posterior(regressionData.toIndexedSeq)\n\n  val posteriorGroup = ui.createGroup("posterior-model")\n  ui.show(posteriorGroup, posterior, "posterior")\n')))}u.isMDXComponent=!0},8891:function(e,t,r){t.Z=r.p+"assets/files/Tutorial09-ec0db7ad4d165cffa6e10d28e3baab74.scala"}}]);