"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[6026],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return m}});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=r.createContext({}),c=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},p=function(e){var t=c(e.components);return r.createElement(l.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},d=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),d=c(n),m=a,h=d["".concat(l,".").concat(m)]||d[m]||u[m]||i;return n?r.createElement(h,o(o({ref:t},p),{},{components:n})):r.createElement(h,o({ref:t},p))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,o=new Array(i);o[0]=d;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:a,o[1]=s;for(var c=2;c<i;c++)o[c]=n[c];return r.createElement.apply(null,o)}return r.createElement.apply(null,n)}d.displayName="MDXCreateElement"},3204:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return s},contentTitle:function(){return l},metadata:function(){return c},toc:function(){return p},default:function(){return d}});var r=n(7462),a=n(3366),i=(n(7294),n(3905)),o=["components"],s={id:"tutorial10",title:"Iterative Closest Points for rigid alignment"},l=void 0,c={unversionedId:"Tutorials/tutorial10",id:"Tutorials/tutorial10",title:"Iterative Closest Points for rigid alignment",description:"The goal in this tutorial is to derive an implementation of the classical Iterative Closest Points (ICP) algorithm",source:"@site/docs/Tutorials/tutorial10.md",sourceDirName:"Tutorials",slug:"/Tutorials/tutorial10",permalink:"/docs/next/Tutorials/tutorial10",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Tutorials/tutorial10.md",tags:[],version:"current",frontMatter:{id:"tutorial10",title:"Iterative Closest Points for rigid alignment"},sidebar:"docs",previous:{title:"Shape completion using GP regression",permalink:"/docs/next/Tutorials/tutorial09"},next:{title:"Model fitting with Iterative Closest Points",permalink:"/docs/next/Tutorials/tutorial11"}},p=[{value:"Related resources",id:"related-resources",children:[],level:5},{value:"Preparation",id:"preparation",children:[],level:5},{value:"Automatic rigid alignment",id:"automatic-rigid-alignment",children:[{value:"Candidate correspondences",id:"candidate-correspondences",children:[],level:3}],level:2}],u={toc:p};function d(e){var t=e.components,s=(0,a.Z)(e,o);return(0,i.kt)("wrapper",(0,r.Z)({},u,s,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"The goal in this tutorial is to derive an implementation of the classical Iterative Closest Points (ICP) algorithm\nin the context of rigid alignment of shapes."),(0,i.kt)("h5",{id:"related-resources"},"Related resources"),(0,i.kt)("p",null,"To enhance your understanding of this tutorial, we recommend the following resources from our ",(0,i.kt)("a",{parentName:"p",href:"https://shapemodelling.cs.unibas.ch/ssm-course/"},"online course"),":"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Superimposing shapes ",(0,i.kt)("a",{parentName:"li",href:"https://www.futurelearn.com/courses/statistical-shape-modelling/3/steps/250330"},"(Article)")),(0,i.kt)("li",{parentName:"ul"},"Model-fitting and correspondence ",(0,i.kt)("a",{parentName:"li",href:"https://www.futurelearn.com/courses/statistical-shape-modelling/3/steps/250371"},"(Video)"))),(0,i.kt)("p",null,"To run the code from this tutorial, download the following Scala file:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{target:"_blank",href:n(7239).Z},"Tutorial10.scala"))),(0,i.kt)("h5",{id:"preparation"},"Preparation"),(0,i.kt)("p",null,"As in the previous tutorials, we start by importing some commonly used objects and initializing the system."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-scala"},"import scalismo.ui.api.*\nimport scalismo.geometry.*\nimport scalismo.common.*\nimport scalismo.mesh.*\nimport scalismo.registration.LandmarkRegistration\nimport scalismo.io.{MeshIO}\nimport scalismo.numerics.UniformMeshSampler3D\nimport breeze.linalg.{DenseMatrix, DenseVector}\n\nimport java.io.File\n\nimport scalismo.utils.Random.FixedSeed.randBasis\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-scala"},"  scalismo.initialize()\n\n  val ui = ScalismoUI()\n")),(0,i.kt)("h2",{id:"automatic-rigid-alignment"},"Automatic rigid alignment"),(0,i.kt)("p",null,"  We start by loading and visualizing two meshes"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-scala"},'  val mesh1 = MeshIO.readMesh(File("datasets/Paola.ply")).get\n  val group1 = ui.createGroup("Dataset 1")\n  val mesh1View = ui.show(group1, mesh1, "mesh1")\n\n  val mesh2 = MeshIO.readMesh(File("datasets/323.ply")).get\n  val group2 = ui.createGroup("Dataset 2")\n  val mesh2View = ui.show(group2, mesh2, "mesh2")\n  mesh2View.color = java.awt.Color.RED\n')),(0,i.kt)("p",null,"As you can see here, the meshes are not aligned. Instead of manually identifying corresponding points as we have done in previous tutorials, we'll employ a more automated approach here, specifically using the Iterative Closest Point (ICP) method. This method allows us to automatically perform the rigid alignment, reducing the need for manual adjustments."),(0,i.kt)("h3",{id:"candidate-correspondences"},"Candidate correspondences"),(0,i.kt)("p",null,"In previous discussions, we found the optimal rigid transformation given a set of correct correspondences. However, this time, we lack those correspondences. This is where the Iterative Closest Point (ICP) algorithm comes in. It approximates correspondences by assuming that the corresponding point is the closest point on the mesh."),(0,i.kt)("p",null,"First, we'll select some points from our mesh. The exact count isn't critical, but we should aim for an approximate uniform distribution across the surface."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-scala"},'  val ptIds = (0 until mesh1.pointSet.numberOfPoints by 50).map(i => PointId(i))\n  ui.show(group1, ptIds.map(id => mesh1.pointSet.point(id)), "selected")\n')),(0,i.kt)("p",null,"Next, we identify corresponding points in the other mesh:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-scala"},"  def attributeCorrespondences(movingMesh: TriangleMesh[_3D], ptIds : Seq[PointId]) : Seq[(Point[_3D], Point[_3D])] = \n    ptIds.map((id : PointId) =>\n      val pt = movingMesh.pointSet.point(id)\n      val closestPointOnMesh2 = mesh2.pointSet.findClosestPoint(pt).point\n      (pt, closestPointOnMesh2)\n    )\n")),(0,i.kt)("p",null,"Here, we didn't use ",(0,i.kt)("inlineCode",{parentName:"p"},"mesh1")," directly, but rather the ",(0,i.kt)("inlineCode",{parentName:"p"},"movingMesh")," argument, which will be iteratively transformed to closely align with our target mesh, ",(0,i.kt)("inlineCode",{parentName:"p"},"mesh2"),"."),(0,i.kt)("p",null,"Let us now visualize these correspondences:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-scala"},'  val correspondences = attributeCorrespondences(mesh1, ptIds)\n  val targetPoints = correspondences.map(pointPair => pointPair._2)\n  ui.show(group2, targetPoints.toIndexedSeq, "correspondences")\n')),(0,i.kt)("p",null,"As expected, the obtained correspondences are clearly not good, as they tend to focus on only one side of the target face. Nevertheless, we can apply Procrustes analysis based on these correspondences and\nretrieve a rigid transformation that brings us closer to the target."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-scala"},'  val rigidTrans =  LandmarkRegistration.rigid3DLandmarkRegistration(correspondences, center = Point3D(0, 0, 0))\n  val transformed = mesh1.transform(rigidTrans)\n  val alignedMeshView = ui.show(group1, transformed, "aligned?")\n  alignedMeshView.color = java.awt.Color.GREEN\n')),(0,i.kt)("p",null,"As expected, this alignment isn't great, given the poor quality of the candidate correspondences. However, it does bring us closer to the target compared to our initial position."),(0,i.kt)("p",null,"The second critical aspect of the ICP algorithm is iterative repetition of these steps, as they often converge. Here's how it works:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-scala"},'  val newCorrespondences = attributeCorrespondences(transformed, ptIds)\n  val newClosestPoints = newCorrespondences.map(pointPair => pointPair._2)\n  ui.show(group2, newClosestPoints.toIndexedSeq, "newCandidateCorr")\n  val newRigidTransformation =\n    LandmarkRegistration.rigid3DLandmarkRegistration(newCorrespondences, center = Point3D(0, 0, 0))\n  val newTransformed = transformed.transform(newRigidTransformation)\n\n  val alignedMeshView2 =  ui.show(group2, newTransformed, "aligned??")\n  alignedMeshView2.color = java.awt.Color.BLUE\n')),(0,i.kt)("p",null,"As you can see, the candidate correspondences are still clearly wrong,\nbut start to be more spread around the target face.\nAlso the resulting rigid transformation seems to bring our mesh a bit closer to the target."),(0,i.kt)("p",null,"Finally, we change our implementation such that we can perform an arbitrary number of iterations:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-scala"},"  def ICPRigidAlign(movingMesh: TriangleMesh[_3D], ptIds : Seq[PointId], numberOfIterations : Int) : TriangleMesh[_3D] = \n    if (numberOfIterations == 0) then \n      movingMesh \n    else \n      val correspondences = attributeCorrespondences(movingMesh, ptIds)\n      val transform = LandmarkRegistration.rigid3DLandmarkRegistration(correspondences, center = Point(0, 0, 0))\n      val transformed = movingMesh.transform(transform)\n      ICPRigidAlign(transformed, ptIds, numberOfIterations - 1)    \n\n")),(0,i.kt)("p",null,"Let's run it with 150 iterations:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-scala"},'\n  val rigidfit = ICPRigidAlign(mesh1, ptIds, 150)\n  val rigidFitView = ui.show(group1, rigidfit, "ICP_rigid_fit")\n  rigidFitView.color = java.awt.Color.YELLOW\n')),(0,i.kt)("p",null,"As you can observe, the quality of the candidate correspondences did indeed result in a proper\n",(0,i.kt)("strong",{parentName:"p"},"automatic")," rigid alignment of Paola to the target. One should not forget, however, that the ICP method is\nvery sensitive to the initial position, and might easily get stuck in a local minimum."))}d.isMDXComponent=!0},7239:function(e,t,n){t.Z=n.p+"assets/files/Tutorial10-5ced1df90fd41afc31f2d39cda234164.scala"}}]);