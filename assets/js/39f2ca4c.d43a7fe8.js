"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[9049],{3905:function(e,t,n){n.d(t,{Zo:function(){return d},kt:function(){return p}});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),c=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},d=function(e){var t=c(e.components);return a.createElement(s.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),u=c(n),p=r,f=u["".concat(s,".").concat(p)]||u[p]||m[p]||o;return n?a.createElement(f,i(i({ref:t},d),{},{components:n})):a.createElement(f,i({ref:t},d))}));function p(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var c=2;c<o;c++)i[c]=n[c];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},8636:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return l},contentTitle:function(){return s},metadata:function(){return c},toc:function(){return d},default:function(){return u}});var a=n(7462),r=n(3366),o=(n(7294),n(3905)),i=["components"],l={id:"tutorial09",title:"Shape completion using GP regression"},s=void 0,c={unversionedId:"Tutorials/tutorial09",id:"version-0.90/Tutorials/tutorial09",title:"Shape completion using GP regression",description:"In this tutorial we will show how GP regression can be used to predict missing parts of a shape.",source:"@site/versioned_docs/version-0.90/Tutorials/tutorial09.md",sourceDirName:"Tutorials",slug:"/Tutorials/tutorial09",permalink:"/docs/Tutorials/tutorial09",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/versioned_docs/version-0.90/Tutorials/tutorial09.md",tags:[],version:"0.90",frontMatter:{id:"tutorial09",title:"Shape completion using GP regression"},sidebar:"docs",previous:{title:"Posterior shape models",permalink:"/docs/Tutorials/tutorial08"},next:{title:"Iterative Closest Points for rigid alignment",permalink:"/docs/Tutorials/tutorial10"}},d=[{value:"Related resources",id:"related-resources",children:[],level:5},{value:"Preparation",id:"preparation",children:[],level:5},{value:"Enlarging the flexibility of a shape model",id:"enlarging-the-flexibility-of-a-shape-model",children:[],level:2}],m={toc:d};function u(e){var t=e.components,l=(0,r.Z)(e,i);return(0,o.kt)("wrapper",(0,a.Z)({},m,l,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"In this tutorial we will show how GP regression can be used to predict missing parts of a shape."),(0,o.kt)("h5",{id:"related-resources"},"Related resources"),(0,o.kt)("p",null,"To run the code from this tutorial, download the following Scala file:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{target:"_blank",href:n(8152).Z},"Tutorial09.scala"))),(0,o.kt)("h5",{id:"preparation"},"Preparation"),(0,o.kt)("p",null,"As in the previous tutorials, we start by importing some commonly used objects and initializing the system."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},"import scalismo.geometry._\nimport scalismo.common._\nimport scalismo.common.interpolation.TriangleMeshInterpolator3D\nimport scalismo.mesh._\nimport scalismo.io.{StatisticalModelIO, MeshIO, LandmarkIO}\nimport scalismo.statisticalmodel._\nimport scalismo.numerics.UniformMeshSampler3D\nimport scalismo.kernels._\nimport breeze.linalg.{DenseMatrix, DenseVector}\n\nimport scalismo.ui.api._\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},"scalismo.initialize()\nimplicit val rng = scalismo.utils.Random(42)\n\nval ui = ScalismoUI()\n")),(0,o.kt)("p",null,"We also load a dataset that we want to reconstruct. In this case, it is a face without nose:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'val noseless = MeshIO.readMesh(new java.io.File("datasets/noseless.ply")).get\n\nval targetGroup = ui.createGroup("target")\nui.show(targetGroup, noseless,"noseless")\n')),(0,o.kt)("p",null,"Finally, we also load the face model."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'val smallModel = StatisticalModelIO.readStatisticalTriangleMeshModel3D(new java.io.File("datasets/model.h5")).get\n')),(0,o.kt)("h2",{id:"enlarging-the-flexibility-of-a-shape-model"},"Enlarging the flexibility of a shape model"),(0,o.kt)("p",null,"The model, which we just loaded, was built from only a small dataset. Therefore, the chances that it manages to\nreconstruct the missing nose properly are rather slim."),(0,o.kt)("p",null,"To increase the shape variability of the model, we add smooth some additional smooth shape deformations,\nmodelled by a GP with symmetric Gaussian kernel. The code should be familiar from the previous tutorials."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'val scalarValuedKernel = GaussianKernel3D(70) * 10.0\n\ncase class XmirroredKernel(kernel: PDKernel[_3D]) extends PDKernel[_3D] {\n    override def domain = EuclideanSpace3D\n    override def k(x: Point[_3D], y: Point[_3D]) = kernel(Point(x(0) * -1f, x(1), x(2)), y)\n}\n\ndef symmetrizeKernel(kernel: PDKernel[_3D]): MatrixValuedPDKernel[_3D] = {\n  val xmirrored = XmirroredKernel(kernel)\n  val k1 = DiagonalKernel(kernel, 3)\n  val k2 = DiagonalKernel(xmirrored * -1f, xmirrored, xmirrored)\n  k1 + k2\n}\n\nval gp = GaussianProcess[_3D, EuclideanVector[_3D]](symmetrizeKernel(scalarValuedKernel))\n\nval lowrankGP = LowRankGaussianProcess.approximateGPCholesky(\n      smallModel.reference,\n      gp,\n      relativeTolerance = 0.5e-1,\n      interpolator = TriangleMeshInterpolator3D[EuclideanVector[_3D]]()\n)\nval model = PointDistributionModel.augmentModel(smallModel, lowrankGP)\n\nval modelGroup = ui.createGroup("face model")\nval ssmView = ui.show(modelGroup, model, "model")\n')),(0,o.kt)("p",null,"The new model should now contain much more flexibility, while still preserving the typical face-specific deformations."),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},"Note: This step here is mainly motivated by the fact that we only have 10 face examples available to build the model. However,\neven if sufficient data is available, it might still be a good idea to slighly enlarge the flexibility of a model\nbefore attempting a reconstruction of missing parts. It gives the model some extra slack to account for\nbias in the data and explain minor shape variations, which have not been prominent in the dataset"),"."),(0,o.kt)("p",null,"Equipped with our new model, we will perform the reconstruction in three steps:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"We fit the face model to the given partial face using Gaussian process regression."),(0,o.kt)("li",{parentName:"ol"},"We restrict the model to the nose part by marginalizing and select a suitable nose shape."),(0,o.kt)("li",{parentName:"ol"},"We choose a suitable nose from the model")),(0,o.kt)("p",null,"As we saw previously, to perform GP regression we need observations of the deformation vectors at some points.\nWe will discussed in ",(0,o.kt)("a",{parentName:"p",href:"./tutorial10"},"Tutorial 10")," how such observations can be obtained fully automatically.\nHere, we have done this already in a separate step and saved 200 corresponding points as landmarks, which we will now load and visualize:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'val referenceLandmarks = LandmarkIO.readLandmarksJson3D(new java.io.File("datasets/modelLandmarks.json")).get\nval referencePoints : Seq[Point[_3D]] = referenceLandmarks.map(lm => lm.point)\nval referenceLandmarkViews = referenceLandmarks.map(lm => ui.show(modelGroup, lm, s"lm-${lm.id}"))\n\n\nval noselessLandmarks = LandmarkIO.readLandmarksJson3D(new java.io.File("datasets/noselessLandmarks.json")).get\nval noselessPoints : Seq[Point[_3D]] = noselessLandmarks.map(lm => lm.point)\nval noselessLandmarkViews = noselessLandmarks.map(lm => ui.show(targetGroup, lm, s"lm-${lm.id}"))\n')),(0,o.kt)("p",null,"These correspondences define how each selected point of the\nmodel should be deformed to its corresponding point on the target mesh.\nIn other words, we ",(0,o.kt)("strong",{parentName:"p"},"observed")," a few deformation vectors at\nthe selected model points. We use these deformation vectors and build\na deformation field:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'val domain = UnstructuredPointsDomain3D(referencePoints.toIndexedSeq)\nval deformations = (0 until referencePoints.size).map(i => noselessPoints(i) - referencePoints(i) )\nval defField = DiscreteField3D(domain, deformations)\nui.show(modelGroup, defField, "partial_Field")\n')),(0,o.kt)("p",null,"We can now perform GP regression and retrieve the rest of the deformations fitting our observations:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-scala"},'val littleNoise = MultivariateNormalDistribution(DenseVector.zeros[Double](3), DenseMatrix.eye[Double](3) * 0.5)\n\nval regressionData = for ((refPoint, noselessPoint) <- referencePoints zip noselessPoints) yield {\n  val refPointId = model.reference.pointSet.findClosestPoint(refPoint).id\n  (refPointId, noselessPoint, littleNoise)\n}\n\nval posterior = model.posterior(regressionData.toIndexedSeq)\n\nval posteriorGroup = ui.createGroup("posterior-model")\nui.show(posteriorGroup, posterior, "posterior")\n')),(0,o.kt)("p",null,"With this posterior model, we get a normal distribution of faces satisfying our observations by having the selected characteristic points at the indicated positions."))}u.isMDXComponent=!0},8152:function(e,t,n){t.Z=n.p+"assets/files/Tutorial09-69f56776234b986794d1d683d308b425.scala"}}]);